---
title: "Coverage vs Acceptance-Error Curves for Conformal\r Classification Models"
abstract: "In this paper, we introduce coverage vs\r acceptance-error graphs as a
  visualization tool for\r comparing the performance of conformal predictors at\r
  a given significance level $\\epsilon$ for any\r k-class classification task with
  k $\\geq$ 2. We show\r that by plotting the performance of each predictor\r for
  different significance levels in $\\epsilon$\r $\\in$ [0, 1], we receive a coverage
  vs\r acceptanceerror curve for that predictor. The area\r under this curve represents
  the probability that the\r p-value of randomly chosen true class-label of any\r
  test instance is greater than the p-value of any\r other false class-label for the
  same or any other\r test instance. This area can be used as a metric for\r predictive
  efficiency of a conformal predictor, when\r the validity has been established. The
  new metric is\r unique in that it is related to the empirical\r coverage rate, and
  extensive experiments confirmed\r its utility and difference from existing predictive\r
  efficiency criteria."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: smirnov23a
month: 0
tex_title: "Coverage vs Acceptance-Error Curves for Conformal\r Classification Models"
firstpage: 534
lastpage: 545
page: 534-545
order: 534
cycles: false
bibtex_author: Smirnov, Evgueni
author:
- given: Evgueni
  family: Smirnov
date: 2023-08-17
address:
container-title: "Proceedings of the Twelfth Symposium on Conformal\r and Probabilistic
  Prediction with Applications"
volume: '204'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 8
  - 17
pdf: https://proceedings.mlr.press/v204/smirnov23a/smirnov23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
